{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import fingerprint_feature_extractor\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from PIL import Image, ImageFilter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T06:55:40.845938Z",
     "start_time": "2024-03-25T06:55:40.832868Z"
    }
   },
   "id": "b1694e8349b9e097",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def binarize_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "\n",
    "def skeletonize_image(binary_image):\n",
    "    skeleton = cv2.ximgproc.thinning(binary_image, thinningType=cv2.ximgproc.THINNING_ZHANGSUEN)\n",
    "    return skeleton\n",
    "\n",
    "\n",
    "def find_special_points(skeleton):\n",
    "    points = []\n",
    "    for i in range(skeleton.shape[0]):\n",
    "        for j in range(skeleton.shape[1]):\n",
    "            if skeleton[i, j] == 255:\n",
    "                points.append((i, j))\n",
    "    return points\n",
    "\n",
    "def compare_fingerprints(points1, points2):\n",
    "    match_score = 0\n",
    "    for point in points1:\n",
    "        if point in points2:\n",
    "            match_score += 1\n",
    "    return match_score"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-25T06:33:48.527945Z",
     "start_time": "2024-03-25T06:33:48.485208Z"
    }
   },
   "id": "initial_id",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def show_compare_images(first_image_path, second_image_path):\n",
    "    img1 = open(first_image_path, 'rb').read()\n",
    "    img2 = open(second_image_path, 'rb').read()\n",
    "    wi1 = widgets.Image(value=img1, format='jpg', width=300, height=400)\n",
    "    wi2 = widgets.Image(value=img2, format='jpg', width=300, height=400)\n",
    "    wid = widgets.HBox([wi1, wi2])\n",
    "    display(wid)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T06:40:37.333890Z",
     "start_time": "2024-03-25T06:40:37.319495Z"
    }
   },
   "id": "3a043727cb3f807a",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01N\\x00\\x00\\x01\\xd0\\x08\\x02\\x00\\x00\\…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3729b42e0bd4cd4b2d7e90fa3456f01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Степень соответствия: 18902\n"
     ]
    }
   ],
   "source": [
    "def test_image_yourself():\n",
    "    binary_image1 = binarize_image('res/print_leha.png')\n",
    "    skeleton1 = skeletonize_image(binary_image1)\n",
    "    points1 = find_special_points(skeleton1)\n",
    "\n",
    "    binary_image2 = binarize_image('res/print_leha.png')\n",
    "    skeleton2 = skeletonize_image(binary_image2)\n",
    "    points2 = find_special_points(skeleton2)\n",
    "\n",
    "    match_score = compare_fingerprints(points1, points2)\n",
    "    show_compare_images('res/print_leha.png', 'res/print_leha.png')\n",
    "    print(f'Степень соответствия: {match_score}')\n",
    "\n",
    "\n",
    "test_image_yourself()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T06:40:45.418516Z",
     "start_time": "2024-03-25T06:40:41.909236Z"
    }
   },
   "id": "dffb9712f816031e",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01N\\x00\\x00\\x01\\xd0\\x08\\x02\\x00\\x00\\…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2961fcc07be04b21888cdc8da0600c5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Степень соответствия: 2952\n"
     ]
    }
   ],
   "source": [
    "def test_different():\n",
    "    binary_image1 = binarize_image('res/print_leha.png')\n",
    "    skeleton1 = skeletonize_image(binary_image1)\n",
    "    points1 = find_special_points(skeleton1)\n",
    "\n",
    "    binary_image2 = binarize_image('res/print_oleg.png')\n",
    "    skeleton2 = skeletonize_image(binary_image2)\n",
    "    points2 = find_special_points(skeleton2)\n",
    "\n",
    "    match_score = compare_fingerprints(points1, points2)\n",
    "    show_compare_images('res/print_leha.png', 'res/print_oleg.png')\n",
    "    print(f'Степень соответствия: {match_score}')\n",
    "\n",
    "\n",
    "test_different()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T06:41:20.509292Z",
     "start_time": "2024-03-25T06:41:15.202897Z"
    }
   },
   "id": "a60c6bb54b447938",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01N\\x00\\x00\\x01\\xd0\\x08\\x02\\x00\\x00\\…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1df7c13d22d456b82100b125d8f43b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Степень соответствия: 8904\n"
     ]
    }
   ],
   "source": [
    "def blur_image(input_path, output_path):\n",
    "    img = Image.open(input_path)\n",
    "    blurred_img = img.filter(ImageFilter.GaussianBlur(radius=2))\n",
    "    blurred_img.save(output_path)\n",
    "\n",
    "\n",
    "def test_blurred_yourself():\n",
    "    binary_image1 = binarize_image('res/print_leha.png')\n",
    "    skeleton1 = skeletonize_image(binary_image1)\n",
    "    points1 = find_special_points(skeleton1)\n",
    "\n",
    "    blur_image(\"res/print_leha.png\", \"res/blurred.png\")\n",
    "\n",
    "    binary_image2 = binarize_image(\"res/blurred.png\")\n",
    "    skeleton2 = skeletonize_image(binary_image2)\n",
    "    points2 = find_special_points(skeleton2)\n",
    "\n",
    "    match_score = compare_fingerprints(points1, points2)\n",
    "    show_compare_images('res/print_leha.png', 'res/blurred.png')\n",
    "    print(f'Степень соответствия: {match_score}')\n",
    "\n",
    "\n",
    "test_blurred_yourself()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T06:41:51.186345Z",
     "start_time": "2024-03-25T06:41:47.174108Z"
    }
   },
   "id": "b1482772b0e0cc3a",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01N\\x00\\x00\\x01\\xd0\\x08\\x02\\x00\\x00\\…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cca86ae9a3d4e9d929fd2f6dee886f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Степень соответствия: 14735\n"
     ]
    }
   ],
   "source": [
    "def lighting_image(img, coef):\n",
    "    img = np.array(img) / 255  # Нормализация значений пикселей к диапазону [0, 1]\n",
    "    img = img + img * coef  # Увеличение яркости на коэффициент\n",
    "    img[img > 1] = 1  # Ограничение значений пикселей до 1\n",
    "    lighted_img = Image.fromarray((img * 255).astype(np.uint8))\n",
    "    lighted_img.save(\"res/lighten.png\")\n",
    "\n",
    "\n",
    "def test_lighten_yourself():\n",
    "    binary_image1 = binarize_image('res/print_leha.png')\n",
    "    skeleton1 = skeletonize_image(binary_image1)\n",
    "    points1 = find_special_points(skeleton1)\n",
    "\n",
    "    img = Image.open('res/print_leha.png')\n",
    "    img_array = np.array(img)\n",
    "    lighting_image(img_array, 0.9)\n",
    "\n",
    "    binary_image2 = binarize_image('res/lighten.png')\n",
    "    skeleton2 = skeletonize_image(binary_image2)\n",
    "    points2 = find_special_points(skeleton2)\n",
    "\n",
    "    match_score = compare_fingerprints(points1, points2)\n",
    "    show_compare_images('res/print_leha.png', 'res/lighten.png')\n",
    "    print(f'Степень соответствия: {match_score}')\n",
    "\n",
    "\n",
    "test_lighten_yourself()   "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T06:43:03.996738Z",
     "start_time": "2024-03-25T06:42:59.542356Z"
    }
   },
   "id": "2e8e75ca43f6467b",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 27\u001B[0m\n\u001B[0;32m     24\u001B[0m     minutiae2 \u001B[38;5;241m=\u001B[39m find_by_features(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mres/print_leha.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28mprint\u001B[39m(compare_minutiae(minutiae1, minutiae2))\n\u001B[1;32m---> 27\u001B[0m \u001B[43mcompare_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[35], line 24\u001B[0m, in \u001B[0;36mcompare_images\u001B[1;34m()\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompare_images\u001B[39m():\n\u001B[0;32m     23\u001B[0m     minutiae1 \u001B[38;5;241m=\u001B[39m find_by_features(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mres/print_leha.png\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 24\u001B[0m     minutiae2 \u001B[38;5;241m=\u001B[39m \u001B[43mfind_by_features\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mres/print_leha.jpg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28mprint\u001B[39m(compare_minutiae(minutiae1, minutiae2))\n",
      "Cell \u001B[1;32mIn[35], line 3\u001B[0m, in \u001B[0;36mfind_by_features\u001B[1;34m(image_path)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_by_features\u001B[39m(image_path):\n\u001B[0;32m      2\u001B[0m     img \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(image_path, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m     FeaturesTerminations, FeaturesBifurcations \u001B[38;5;241m=\u001B[39m \u001B[43mfingerprint_feature_extractor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_minutiae_features\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[43mspuriousMinutiaeThresh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43minvertImage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshowResult\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43msaveResult\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     terminations \u001B[38;5;241m=\u001B[39m [(feature\u001B[38;5;241m.\u001B[39mlocX, feature\u001B[38;5;241m.\u001B[39mlocY, feature\u001B[38;5;241m.\u001B[39mOrientation, feature\u001B[38;5;241m.\u001B[39mType) \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m FeaturesTerminations]\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [(feature\u001B[38;5;241m.\u001B[39mlocX, feature\u001B[38;5;241m.\u001B[39mlocY, feature\u001B[38;5;241m.\u001B[39mOrientation, feature\u001B[38;5;241m.\u001B[39mType) \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m FeaturesBifurcations]\n",
      "File \u001B[1;32m~\\PycharmProjects\\Lab4\\.venv\\lib\\site-packages\\fingerprint_feature_extractor\\__init__.py:192\u001B[0m, in \u001B[0;36mextract_minutiae_features\u001B[1;34m(img, spuriousMinutiaeThresh, invertImage, showResult, saveResult)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (invertImage):\n\u001B[0;32m    190\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;241m-\u001B[39m img;\n\u001B[1;32m--> 192\u001B[0m FeaturesTerm, FeaturesBif \u001B[38;5;241m=\u001B[39m \u001B[43mfeature_extractor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextractMinutiaeFeatures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    194\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (saveResult):\n\u001B[0;32m    195\u001B[0m     feature_extractor\u001B[38;5;241m.\u001B[39msaveResult(FeaturesTerm, FeaturesBif)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Lab4\\.venv\\lib\\site-packages\\fingerprint_feature_extractor\\__init__.py:138\u001B[0m, in \u001B[0;36mFingerprintFeatureExtractor.extractMinutiaeFeatures\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mextractMinutiaeFeatures\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__skeletonize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__getTerminationBifurcation()\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__cleanMinutiae(img)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Lab4\\.venv\\lib\\site-packages\\fingerprint_feature_extractor\\__init__.py:27\u001B[0m, in \u001B[0;36mFingerprintFeatureExtractor.__skeletonize\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__skeletonize\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[1;32m---> 27\u001B[0m     img \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39muint8(\u001B[43mimg\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m128\u001B[39;49m)\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_skel \u001B[38;5;241m=\u001B[39m skimage\u001B[38;5;241m.\u001B[39mmorphology\u001B[38;5;241m.\u001B[39mskeletonize(img)\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_skel \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39muint8(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_skel) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m255\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: '>' not supported between instances of 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "\n",
    "def find_by_features(image_path):\n",
    "    img = cv2.imread(image_path, 0)\n",
    "    FeaturesTerminations, FeaturesBifurcations = fingerprint_feature_extractor.extract_minutiae_features(\n",
    "        img,\n",
    "        spuriousMinutiaeThresh=10,\n",
    "        invertImage=False,\n",
    "        showResult=True,\n",
    "        saveResult=True)\n",
    "    terminations = [(feature.locX, feature.locY, feature.Orientation, feature.Type) for feature in FeaturesTerminations]\n",
    "    return [(feature.locX, feature.locY, feature.Orientation, feature.Type) for feature in FeaturesBifurcations]\n",
    "\n",
    "def compare_minutiae(minutiae1, minutiae2):\n",
    "    scores = []\n",
    "    for m1 in minutiae1:\n",
    "        for m2 in minutiae2:\n",
    "            score = np.linalg.norm(m1 - m2) # Евклидово расстояние\n",
    "            scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def compare_images():\n",
    "    minutiae1 = find_by_features(\"res/print_leha.png\")\n",
    "    minutiae2 = find_by_features(\"res/print_leha.jpg\")\n",
    "    print(compare_minutiae(minutiae1, minutiae2))\n",
    "    \n",
    "#compare_images()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:02:12.809355Z",
     "start_time": "2024-03-25T07:01:08.137230Z"
    }
   },
   "id": "f35796fd0248f92b",
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
